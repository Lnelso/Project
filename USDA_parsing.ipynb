{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import json\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# files paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_des_path = \"data/FOOD_DES.txt\"\n",
    "food_groups_path = \"data/FD_GROUP.txt\"\n",
    "nut_data_path = \"data/NUT_DATA.txt\"\n",
    "nut_def_path = \"data/NUTR_DEF.txt\"\n",
    "\n",
    "all_paths = [food_des_path, food_groups_path, nut_data_path, nut_def_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tilde removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text columns are indicated by '~', remove them\n",
    "for p in all_paths :\n",
    "    string = open(p).read()\n",
    "    new_str = re.sub('[~]', '', string)\n",
    "    open(p, 'w').write(new_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food group description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"food_group_id\", \"food_group_name\"]\n",
    "\n",
    "food_groups = pd.read_csv(food_groups_path, sep=\"^\", encoding=\"ISO-8859-1\", names=columns, header=None)\n",
    "\n",
    "food_groups.set_index(\"food_group_id\", inplace=True)\n",
    "\n",
    "food_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# food description table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singularize_word(x) :\n",
    "    if engine.singular_noun(x) :\n",
    "        return engine.singular_noun(x)\n",
    "    else :\n",
    "        return x\n",
    "        \n",
    "def format_long_des(x) :\n",
    "        \n",
    "    #decompose description\n",
    "    words = [c.strip().lower().split(' ') for c in x.split(\",\")]\n",
    "    \n",
    "    #singularize words\n",
    "    sing_words = [[singularize_word(x) for x in c] for c in words]\n",
    "    \n",
    "    #rebuild description\n",
    "    return \",\".join([\" \".join(c) for c in sing_words])\n",
    "\n",
    "\n",
    "\n",
    "use_cols = [0, 1, 2, 4]\n",
    "engine = inflect.engine()\n",
    "\n",
    "columns = [\"food_id\", \"food_group_id\", \"long_description\", \"common_names\"]\n",
    "\n",
    "food_des = pd.read_csv(food_des_path, sep=\"^\", encoding=\"ISO-8859-1\", names=columns, usecols=use_cols, header=None)\n",
    "food_des['long_description'] = food_des['long_description'].apply(lambda x : format_long_des(x))\n",
    "\n",
    "\n",
    "#food_des['categories'] = food_des['long_description'].apply(lambda x : [c.strip() for c in x.split(\",\")])\n",
    "food_des['categories'] = food_des['long_description'].apply(lambda x : \" \".join([c.strip() for c in x.split(\",\")[:2]]))\n",
    "food_des = food_des.drop_duplicates(subset = ['categories'])\n",
    "food_des = food_des.drop(\"long_description\", axis=1)\n",
    "food_des['categories'] = food_des['categories'].apply(lambda x : x.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we decide to drop :\n",
    "\n",
    "* Baby food (300)\n",
    "* dressing in 400\n",
    "* soup in 600\n",
    "* Breakfast Cereals (800)\n",
    "* Beverages (1400)\n",
    "* Baked products (1800) \n",
    "* Sweets (1900) except Baking products (chocolate)\n",
    "* Fast Foods (2100)\n",
    "* Meals, Entrees, and Side Dishes (2200)\n",
    "* Snacks (2500)\n",
    "* Restaurant food (3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(food_des.count(), \"\\n\")\n",
    "\n",
    "#drop whole categories\n",
    "food_des = food_des[~food_des[\"food_group_id\"].isin([300, 800, 1400, 1800, 2100, 2200, 2500, 3600])]\n",
    "\n",
    "print(food_des.count(), \"\\n\")\n",
    "\n",
    "#drop parts of categories\n",
    "\n",
    "food_des = food_des[~((food_des[\"food_group_id\"]==400) & (food_des['categories'].apply(lambda x : \"dressing\" in x)))]\n",
    "food_des = food_des[~((food_des[\"food_group_id\"]==600) & (food_des['categories'].apply(lambda x : \"soup\" in x)))]\n",
    "food_des = food_des[~((food_des[\"food_group_id\"]==1900) & (food_des['categories'].apply(lambda x : \"baking\" in x)))]\n",
    "\n",
    "print(food_des.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recipe Ingredients loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = json.load(open(\"generated/ingredients_count.json\"))\n",
    "ingredients = list(ingredients['count'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all rows that contain no ingredients words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nb_in_ingredients(categories_words(food_des['categories'].values[c])) for c in range(1, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def categories_words(cat) :\n",
    "    return set([x.strip() for c in cat for x in c.strip().split(\" \")])\n",
    "\n",
    "#build set with all ingredient words\n",
    "ingredients_words = set(\" \".join(ingredients).split(\" \"))\n",
    "\n",
    "#build set of all distinct category words\n",
    "category_words = set(list(itertools.chain.from_iterable([x.split(' ') for c in food_des[\"categories\"].values for x in c])))\n",
    "\n",
    "\n",
    "\n",
    "# all category words not contained in the ingredients\n",
    "print(len(category_words - ingredients_words))\n",
    "\n",
    "# all ingredient words not contained in the categories\n",
    "print(len(ingredients_words - category_words))\n",
    "\n",
    "def nb_in_ingredients(words_set) :\n",
    "    return len(words_set.intersection(ingredients_words))\n",
    "\n",
    "\n",
    "food_des['common_db_words'] = food_des['categories'].apply(lambda x : nb_in_ingredients(categories_words(x)))\n",
    "food_des[food_des['common_db_words'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing = ingredients[1]\n",
    "print(\"search for \", ing)\n",
    "food_des[food_des['categories'].apply(lambda x : len(set(x).intersection(set(ing.split(\" \")))) != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 1 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define categories\n",
    "type_1_categories = set([\"cooked\", \"roasted\", \"boiled\", \"grilled\", \"braised\", \n",
    "                     \"ready-to-serve\", \"fried\", \"baked\", \"pan-fried\"])\n",
    "\n",
    "print(\"items count before type 1 deletion : \", len(food_des))\n",
    "\n",
    "#delete items that have type 1 categories\n",
    "food_des = food_des[food_des['categories'].apply(lambda x : len(set(x).intersection(type_1_categories)) == 0)]\n",
    "\n",
    "print(\"items count after type 1 deletion : \", len(food_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_des.head(1)[\"nb_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ingredient(ingredient) :\n",
    "    print(\"search for \", ingredient)\n",
    "    ing_words = set(ingredient.split(\" \"))    \n",
    "\n",
    "    food_des[\"nb_w\"] = food_des[\"categories\"].apply(lambda x : len(set(x).intersection(ing_words)) / len(set(x)))\n",
    "    result = food_des.sort_values(by=['nb_w'], ascending=False).head(1)\n",
    "    \n",
    "    \n",
    "    if result[\"nb_w\"].values[0] != 0 :\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        print(\"no result\")\n",
    "    \n",
    "    return \n",
    "    \n",
    "search_ingredient(\"honey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nutrient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [0, 1, 2]\n",
    "\n",
    "columns = [\"food_id\", \"nutrient_id\", \"nutr_per_100g\"]\n",
    "\n",
    "nut_data = pd.read_csv(nut_data_path, sep=\"^\", encoding=\"ISO-8859-1\", names=columns, usecols=use_cols, header=None)\n",
    "\n",
    "nut_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table to have all nutrients per food_id\n",
    "nut_data = nut_data.pivot(index='food_id', columns='nutrient_id', values='nutr_per_100g')\n",
    "nut_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nutrient definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [0, 1, 2, 3]\n",
    "\n",
    "columns = [\"nutrient_id\", \"units\", \"tagname\", \"description\"]\n",
    "\n",
    "nut_def = pd.read_csv(nut_def_path, sep=\"^\", encoding=\"ISO-8859-1\", names=columns, usecols=use_cols, header=None)\n",
    "\n",
    "nut_def.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wtf\n",
    "nut_def[[\"description\", \"tagname\"]][80:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# food profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore this cell\n",
    "def group_id(group_name) :\n",
    "    return food_groups.index[food_groups[\"food_group_name\"] == group_name].tolist()[0]\n",
    "\n",
    "\n",
    "#retrieve nteresting ids\n",
    "fruits_group_id = group_id(\"~Fruits and Fruit Juices~\")\n",
    "vegetables_goup_id = group_id(\"~Vegetables and Vegetable Products~\")\n",
    "spices_group_id = group_id(\"~Spices and Herbs~\")\n",
    "nut_group_id = group_id(\"~Nut and Seed Products~\")\n",
    "\n",
    "print(\"fruit id : \", fruits_group_id)\n",
    "\n",
    "#retrieve food description\n",
    "all_fruits_names = food_des[(food_des[\"food_group_id\"] == fruits_group_id)]\n",
    "all_fruits_names = all_fruits_names[all_fruits_names[\"short_description\"].str.contains(\"RAW\") \n",
    "                                   & ~all_fruits_names[\"short_description\"].str.contains(\"SMOOTHIE\")\n",
    "                                   & ~all_fruits_names[\"short_description\"].str.contains(\"CND\")]\n",
    "\n",
    "all_fruits_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search carrot\n",
    "word = \"Carrot\"\n",
    "food_des[food_des[\"long_description\"].str.contains(word)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
