{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get fruits and vegetables names and urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First page of vegetable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(\"https://en.wikipedia.org/wiki/List_of_vegetables\") \n",
    "res = BeautifulSoup(html.read(),\"html5lib\")\n",
    "all_urls = sum([[ c.find(\"a\")['href'] for c in res.findAll(\"table\")[i].findAll(\"tr\")][1:] for i in range(7)], [])\n",
    "all_names = sum([[ c.find(\"a\").text for c in res.findAll(\"table\")[i].findAll(\"tr\")][1:] for i in range(7)], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second page of vegetable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(\"https://en.wikipedia.org/wiki/List_of_culinary_fruits\") \n",
    "res = BeautifulSoup(html.read(),\"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names = \n",
    "true_names = []\n",
    "true_urls = []\n",
    "\n",
    "candidates = [c.findAll(\"li\") for c in res.findAll(\"div\", {\"class\": \"div-col columns column-width\"})][:24]\n",
    "    \n",
    "for candidate in candidates :\n",
    "    \n",
    "    for b in candidate :   \n",
    "        \n",
    "        info = b.find(\"a\")\n",
    "        \n",
    "        if info is not None :\n",
    "            #print(b)\n",
    "            true_names.append(info.text)\n",
    "            true_urls.append(info[\"href\"])\n",
    "    \n",
    "    \n",
    "#len(true_names)\n",
    "#len(true_urls)\n",
    "\n",
    "all_names.extend(true_names)\n",
    "all_urls.extend(true_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amount parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_amount(name, amount) :\n",
    "    \n",
    "    try :\n",
    "    \n",
    "        if 'g' not in amount :\n",
    "            if 'IU' not in amount :\n",
    "                return 0\n",
    "            else :\n",
    "\n",
    "                if '%' in amount :            \n",
    "                    #get rid of %\n",
    "                    if amount.index('%') < amount.index('U') :\n",
    "                        amount = amount[amount.index('%')+1:amount.index('U')]\n",
    "\n",
    "                    else :\n",
    "                        amount = amount[:amount.index('U')]\n",
    "\n",
    "                #get rid of UI\n",
    "                amount = float(re.sub('[UI]','',amount).strip())\n",
    "\n",
    "                #see https://en.wikipedia.org/wiki/International_unit#Mass_equivalents_of_1_IU\n",
    "                if name == \"Vitamin A\" :\n",
    "                    amount = amount * 0.0006\n",
    "\n",
    "                elif name == \"Vitamin C\" :\n",
    "                    amount = amount * 0.05\n",
    "\n",
    "                elif name == \"Vitamin D\" :\n",
    "                    amount = (amount / 40) * 0.001\n",
    "\n",
    "                elif name == \"Vitamin E\" :\n",
    "                    amount = amount * 2/3\n",
    "\n",
    "                else : \n",
    "                    print(\"unknown value for \", amount , \"and name \", name)\n",
    "                    return -1\n",
    "\n",
    "\n",
    "        elif '%' not in amount :\n",
    "\n",
    "            amount = amount[:amount.index('g')]\n",
    "\n",
    "            if len(amount.replace(\"µ\", '')) != len(amount) or  len(re.sub('[μ]','',amount)) != len(amount):\n",
    "\n",
    "                amount = re.sub('[μ]','',amount)\n",
    "                amount = amount.replace(\"µ\", '')\n",
    "                return str(float(re.sub('[mgμ]','',amount).strip())/1000.0)\n",
    "\n",
    "            elif 'm' not in amount :\n",
    "                return str(float(re.sub('[mgμ]','',amount).strip())*1000.0)\n",
    "\n",
    "            else :\n",
    "                return re.sub('[mμg]','',amount).strip()\n",
    "\n",
    "\n",
    "        else :\n",
    "\n",
    "            to_parse = \"\"\n",
    "\n",
    "            #determine if % is before or after g\n",
    "            if amount.index('%') < amount.index('g') :\n",
    "                to_parse = amount[amount.index('%')+1:amount.index('g')]\n",
    "\n",
    "            else :\n",
    "                to_parse = amount[:amount.index('g')]\n",
    "\n",
    "            if len(to_parse.replace(\"µ\", '')) != len(to_parse) or len(re.sub('[μ]','',to_parse)) != len(to_parse):\n",
    "\n",
    "                to_parse = to_parse.replace(\"µ\", '')\n",
    "                to_parse = re.sub('[μ]','',to_parse)\n",
    "                return str(float(re.sub('[mgμ]','',to_parse).strip())/1000.0)\n",
    "\n",
    "            elif 'm' not in to_parse :\n",
    "                return str(float(re.sub('[mgμ]','',to_parse).strip())*1000.0)\n",
    "\n",
    "            else :\n",
    "                return re.sub('[mgμ]','',to_parse).strip()\n",
    "    except :\n",
    "        return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load wanted elements names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alpha-linoleic acid', 'Biotin', 'Calcium', 'Carbohydrate',\n",
       "       'Chloride', 'Choline', 'Chromium', 'Copper', 'Fat', 'Fiber',\n",
       "       'Fluoride', 'Folate', 'Iodine', 'Iron', 'Linoleic acid',\n",
       "       'Magnesium', 'Manganese', 'Molybdenum', 'Monousaturated fat',\n",
       "       'Niacin', 'Pantothenic acid', 'Phosphorus', 'Polyunsaturated fat',\n",
       "       'Potassium', 'Protein', 'Riboflavin', 'Saturated fat', 'Selenium',\n",
       "       'Sodium', 'Sugar', 'Thiamin', 'Vitamin A', 'Vitamin B6',\n",
       "       'Vitamin B12', 'Vitamin C', 'Vitamin D', 'Vitamin E', 'Vitamin K',\n",
       "       'Water', 'Zinc'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements_names = pd.read_excel('data/RDI.xlsx')['element'].values\n",
    "elements_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look up the wikipedia tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nutritional_facts(url) :\n",
    "    try : \n",
    "        html = urlopen(url) \n",
    "        res = BeautifulSoup(html.read(),\"html5lib\");\n",
    "        \n",
    "        food = res.find(\"h1\").text\n",
    "\n",
    "        nutritional_facts = {}\n",
    "\n",
    "        table = res.find(\"table\", {\"class\": \"infobox nowrap\"}) \n",
    "        table_body = table.find('tbody')\n",
    "\n",
    "\n",
    "        rows = table_body.find_all('tr')\n",
    "    except :\n",
    "        print(\"No information for \", url, '\\n')\n",
    "        return None \n",
    "       \n",
    "    \n",
    "    for row in rows:\n",
    "\n",
    "        nut_element = \"\"\n",
    "\n",
    "        valid_name = False\n",
    "        found_name = \"\"\n",
    "        \n",
    "        try :\n",
    "        \n",
    "            #find elements names\n",
    "            elem = row.find('th') \n",
    "\n",
    "            if elem is not None :\n",
    "                name = elem.find('a') \n",
    "\n",
    "                if name is None and elem.text is not None :\n",
    "                    name = elem\n",
    "\n",
    "\n",
    "                if name is not None :\n",
    "\n",
    "                    #check if the name contains something interesting\n",
    "                    matching = [c.lower() in name.text.lower() for c in elements_names]\n",
    "                    valid_name  = sum(matching) >= 1            \n",
    "\n",
    "                    if valid_name :\n",
    "                        matching_name = elements_names[matching.index(True)]\n",
    "                        found_name = name.text\n",
    "                        nut_element = matching_name\n",
    "\n",
    "        except :\n",
    "            valid_name = False\n",
    "                        \n",
    "        #find element amount\n",
    "\n",
    "\n",
    "        if valid_name :\n",
    "            \n",
    "            amount = row.find('td')\n",
    "\n",
    "            if amount is not None :  \n",
    "\n",
    "                #hard special case\n",
    "                if found_name == \"Vitamin A equiv.\" :\n",
    "                    whole_string = amount.text\n",
    "                    div_strings = [amount.find_all('div')[i].text for i in range(len(amount.find_all('div')))]\n",
    "                    div_strings = sorted(div_strings, key = len, reverse = True)\n",
    "\n",
    "                    #print(\"whole string : \", whole_string)\n",
    "                    #print(\"div_strings : \", div_strings)\n",
    "\n",
    "                    original_string = whole_string\n",
    "\n",
    "                    for div_string in div_strings :\n",
    "                        whole_string = whole_string.replace(div_string, '')\n",
    "\n",
    "                    if len(whole_string) != 0 :\n",
    "                        #print(\"sent to parsing : \", whole_string)\n",
    "                        nutritional_facts[matching_name] = parse_amount(nut_element, whole_string)\n",
    "\n",
    "                    else :\n",
    "                        nutritional_facts[matching_name] = sum([float(parse_amount(nut_element, d)) for d in div_strings])\n",
    "\n",
    "                elif 'div' not in str(amount) :\n",
    "\n",
    "                    #print(\"sent to parsing : \", amount.text)\n",
    "                    nutritional_facts[matching_name] = parse_amount(nut_element, amount.text)\n",
    "\n",
    "                else :              \n",
    "\n",
    "                    #amount = parse_amount(amount.find_all('div')[0].text)\n",
    "                    #print(\"sent to parsing : \", amount.text)\n",
    "                    amount = parse_amount(nut_element, amount.text)\n",
    "                    nutritional_facts[matching_name] = amount\n",
    "\n",
    "    return nutritional_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing  /wiki/Amaranth ...\n",
      "analyzing  /wiki/Arugula ...\n",
      "No information for  Eruca sativa \n",
      "\n",
      "analyzing  /wiki/Beet ...\n",
      "analyzing  /wiki/Chinese_cabbage ...\n",
      "No information for  Chinese cabbage \n",
      "\n",
      "analyzing  /wiki/Borage ...\n",
      "No information for  Borage \n",
      "\n",
      "analyzing  /wiki/Broccoli ...\n",
      "analyzing  /wiki/Brussels_sprout ...\n",
      "analyzing  /wiki/Cabbage ...\n",
      "analyzing  /wiki/Hypochaeris_radicata ...\n",
      "No information for  Hypochaeris radicata \n",
      "\n",
      "analyzing  /wiki/Celery ...\n",
      "analyzing  /wiki/Celtuce ...\n",
      "analyzing  /wiki/Chaya_(plant) ...\n",
      "No information for  Cnidoscolus aconitifolius \n",
      "\n",
      "analyzing  /wiki/Stellaria ...\n",
      "No information for  Stellaria \n",
      "\n",
      "analyzing  /wiki/Chicory ...\n",
      "analyzing  /wiki/Chinese_mallow ...\n",
      "No information for  Malva verticillata \n",
      "\n",
      "analyzing  /wiki/Garland_Chrysanthemum ...\n",
      "analyzing  /wiki/Collard_greens ...\n",
      "analyzing  /wiki/Common_purslane ...\n",
      "analyzing  /wiki/Corn_salad ...\n",
      "analyzing  /wiki/Garden_cress ...\n",
      "analyzing  /wiki/Dandelion ...\n",
      "No information for  Taraxacum \n",
      "\n",
      "analyzing  /wiki/Dill ...\n",
      "analyzing  /wiki/Endive ...\n",
      "analyzing  /wiki/Chenopodium_album ...\n",
      "analyzing  /wiki/Fiddlehead ...\n",
      "No information for  Fiddlehead fern \n",
      "\n",
      "analyzing  /wiki/Telfairia_occidentalis ...\n",
      "No information for  Telfairia occidentalis \n",
      "\n",
      "analyzing  /wiki/Eruca_sativa ...\n",
      "No information for  Eruca sativa \n",
      "\n",
      "analyzing  /wiki/Golden_samphire ...\n",
      "No information for  Golden samphire \n",
      "\n",
      "analyzing  /wiki/Good_King_Henry ...\n",
      "No information for  Blitum bonus-henricus \n",
      "\n",
      "analyzing  /wiki/Grape ...\n",
      "analyzing  /wiki/Plantago_major ...\n",
      "No information for  Plantago major \n",
      "\n",
      "analyzing  /wiki/Kai-lan ...\n",
      "No information for  Gai lan \n",
      "\n",
      "analyzing  /wiki/Kale ...\n",
      "analyzing  /wiki/Komatsuna ...\n",
      "analyzing  /wiki/Adansonia ...\n",
      "No information for  Adansonia \n",
      "\n",
      "analyzing  /wiki/Talinum_fruticosum ...\n",
      "No information for  Talinum fruticosum \n",
      "\n",
      "analyzing  /wiki/Corn_salad ...\n",
      "analyzing  /wiki/Lamb%27s_quarters ...\n",
      "No information for  Lamb's quarters \n",
      "\n",
      "analyzing  /wiki/Land_cress ...\n",
      "No information for  Barbarea verna \n",
      "\n",
      "analyzing  /wiki/Lettuce ...\n",
      "analyzing  /wiki/Houttuynia_cordata ...\n",
      "No information for  Houttuynia cordata \n",
      "\n",
      "analyzing  /wiki/Basella_alba ...\n",
      "analyzing  /wiki/Malvaceae ...\n",
      "No information for  Malvaceae \n",
      "\n",
      "analyzing  /wiki/Melokhia ...\n",
      "analyzing  /wiki/Miner%27s_lettuce ...\n",
      "No information for  Claytonia perfoliata \n",
      "\n",
      "analyzing  /wiki/Mizuna_greens ...\n",
      "No information for  Mizuna \n",
      "\n",
      "analyzing  /wiki/Sinapis_alba ...\n",
      "No information for  White mustard \n",
      "\n",
      "analyzing  /wiki/Napa_cabbage ...\n",
      "analyzing  /wiki/Tetragonia ...\n",
      "No information for  Tetragonia \n",
      "\n",
      "analyzing  /wiki/Atriplex ...\n",
      "No information for  Atriplex \n",
      "\n",
      "analyzing  /wiki/Chinese_cabbage ...\n",
      "No information for  Chinese cabbage \n",
      "\n",
      "analyzing  /wiki/Paracress ...\n",
      "No information for  Acmella oleracea \n",
      "\n",
      "analyzing  /wiki/Pea ...\n",
      "analyzing  /wiki/Phytolacca_americana ...\n",
      "analyzing  /wiki/Radicchio ...\n",
      "analyzing  /wiki/Rapini ...\n",
      "analyzing  /wiki/Rock_samphire ...\n",
      "No information for  Crithmum \n",
      "\n",
      "analyzing  /wiki/Sculpit ...\n",
      "No information for  Silene vulgaris \n",
      "\n",
      "analyzing  /wiki/Sea_beet ...\n",
      "No information for  Sea beet \n",
      "\n",
      "analyzing  /wiki/Sea_kale ...\n",
      "No information for  Crambe maritima \n",
      "\n",
      "analyzing  /wiki/Crassocephalum ...\n",
      "No information for  Crassocephalum \n",
      "\n",
      "analyzing  /wiki/Celosia_argentea ...\n",
      "No information for  Celosia argentea \n",
      "\n",
      "analyzing  /wiki/Sorrel ...\n",
      "No information for  Sorrel \n",
      "\n",
      "analyzing  /wiki/Sour_cabbage ...\n",
      "No information for  Whole sour cabbage \n",
      "\n",
      "analyzing  /wiki/Spinach ...\n",
      "analyzing  /wiki/Portulaca_oleracea ...\n",
      "analyzing  /wiki/Chard ...\n",
      "analyzing  /wiki/Tatsoi ...\n",
      "No information for  Tatsoi \n",
      "\n",
      "analyzing  /wiki/Turnip ...\n",
      "analyzing  /wiki/Watercress ...\n",
      "analyzing  /wiki/Ipomoea_aquatica ...\n",
      "analyzing  /wiki/Wheatgrass ...\n",
      "No information for  Wheatgrass \n",
      "\n",
      "analyzing  /wiki/Achillea_millefolium ...\n",
      "No information for  Achillea millefolium \n",
      "\n",
      "analyzing  /wiki/Rapeseed ...\n",
      "No information for  Rapeseed \n",
      "\n",
      "analyzing  /wiki/Capsella_bursa-pastoris ...\n",
      "No information for  Capsella bursa-pastoris \n",
      "\n",
      "analyzing  /wiki/Avocado ...\n",
      "analyzing  /wiki/Bell_pepper ...\n",
      "analyzing  /wiki/Momordica_charantia ...\n",
      "analyzing  /wiki/Chayote ...\n",
      "analyzing  /wiki/Cucumber ...\n",
      "analyzing  /wiki/Coccinia_grandis ...\n",
      "No information for  Coccinia grandis \n",
      "\n",
      "analyzing  /wiki/Eggplant ...\n",
      "analyzing  /wiki/Luffa ...\n",
      "No information for  Luffa \n",
      "\n",
      "analyzing  /wiki/Olive ...\n",
      "analyzing  /wiki/Pumpkin ...\n",
      "analyzing  /wiki/Squash_(plant) ...\n",
      "analyzing  /wiki/Capsicum ...\n",
      "No information for  Capsicum \n",
      "\n",
      "analyzing  /wiki/Tinda ...\n",
      "No information for  Tinda \n",
      "\n",
      "analyzing  /wiki/Tomatillo ...\n",
      "No information for  Tomatillo \n",
      "\n",
      "analyzing  /wiki/Tomato ...\n",
      "analyzing  /wiki/Vanilla ...\n",
      "No information for  Vanilla \n",
      "\n",
      "analyzing  /wiki/Cucumis_anguria ...\n",
      "No information for  Cucumis anguria \n",
      "\n",
      "analyzing  /wiki/Water_melon ...\n",
      "analyzing  /wiki/Winter_melon ...\n",
      "analyzing  /wiki/Zucchini ...\n",
      "No information for  Zucchini \n",
      "\n",
      "analyzing  /wiki/Artichoke ...\n",
      "analyzing  /wiki/Broccoli ...\n",
      "analyzing  /wiki/Broccolini ...\n",
      "No information for  Broccolini \n",
      "\n",
      "analyzing  /wiki/Caper ...\n",
      "analyzing  /wiki/Cauliflower ...\n",
      "analyzing  /wiki/Daylily ...\n",
      "No information for  Daylily \n",
      "\n",
      "analyzing  /wiki/Loroco ...\n",
      "No information for  Fernaldia pandurata \n",
      "\n",
      "analyzing  /wiki/Zucchini ...\n",
      "No information for  Zucchini \n",
      "\n",
      "analyzing  /wiki/Zucchini ...\n",
      "No information for  Zucchini \n",
      "\n",
      "analyzing  /wiki/Apios_americana ...\n",
      "No information for  Apios americana \n",
      "\n",
      "analyzing  /wiki/Azuki_bean ...\n",
      "analyzing  /wiki/Black-eyed_pea ...\n",
      "analyzing  /wiki/Chickpea ...\n",
      "analyzing  /wiki/Common_bean ...\n",
      "No information for  Phaseolus vulgaris \n",
      "\n",
      "analyzing  /wiki/Drumstick_(vegetable) ...\n",
      "analyzing  /wiki/Hyacinth_Bean ...\n",
      "analyzing  /wiki/Vicia_faba ...\n",
      "analyzing  /wiki/Chickpea ...\n",
      "analyzing  /wiki/Green_bean ...\n",
      "analyzing  /wiki/Guar ...\n",
      "No information for  Guar \n",
      "\n",
      "analyzing  /wiki/Horse_gram ...\n",
      "No information for  Macrotyloma uniflorum \n",
      "\n",
      "analyzing  /wiki/Lathyrus_sativus ...\n",
      "No information for  Lathyrus sativus \n",
      "\n",
      "analyzing  /wiki/Lentil ...\n",
      "analyzing  /wiki/Phaseolus_lunatus ...\n",
      "analyzing  /wiki/Moth_bean ...\n",
      "analyzing  /wiki/Mung_bean ...\n",
      "analyzing  /wiki/Okra ...\n",
      "analyzing  /wiki/Pea ...\n",
      "analyzing  /wiki/Peanut ...\n",
      "analyzing  /wiki/Pigeon_pea ...\n",
      "analyzing  /wiki/Ricebean ...\n",
      "No information for  Vigna umbellata \n",
      "\n",
      "analyzing  /wiki/Runner_bean ...\n",
      "No information for  Phaseolus coccineus \n",
      "\n",
      "analyzing  /wiki/Snap_pea ...\n",
      "analyzing  /wiki/Snow_pea ...\n",
      "analyzing  /wiki/Soybean ...\n",
      "analyzing  /wiki/Lupinus_mutabilis ...\n",
      "No information for  Lupinus mutabilis \n",
      "\n",
      "analyzing  /wiki/Tepary_bean ...\n",
      "No information for  Phaseolus acutifolius \n",
      "\n",
      "analyzing  /wiki/Urad_(bean) ...\n",
      "analyzing  /wiki/Mucuna_pruriens ...\n",
      "No information for  Mucuna pruriens \n",
      "\n",
      "analyzing  /wiki/Winged_bean ...\n",
      "analyzing  /wiki/Yardlong_bean ...\n",
      "analyzing  /wiki/Asparagus ...\n",
      "analyzing  /wiki/Cardoon ...\n",
      "analyzing  /wiki/Celeriac ...\n",
      "analyzing  /wiki/Celery ...\n",
      "analyzing  /wiki/Chives ...\n",
      "analyzing  /wiki/Elephant_garlic ...\n",
      "No information for  Elephant garlic \n",
      "\n",
      "analyzing  /wiki/Fennel ...\n",
      "analyzing  /wiki/Garlic ...\n",
      "analyzing  /wiki/Allium_tuberosum ...\n",
      "No information for  Allium tuberosum \n",
      "\n",
      "analyzing  /wiki/Kohlrabi ...\n",
      "analyzing  /wiki/Kurrat ...\n",
      "No information for  Allium ampeloprasum \n",
      "\n",
      "analyzing  /wiki/Lemongrass ...\n",
      "No information for  Cymbopogon \n",
      "\n",
      "analyzing  /wiki/Leek ...\n",
      "analyzing  /wiki/Nelumbo_nucifera ...\n",
      "analyzing  /wiki/Nopal ...\n",
      "No information for  Nopal \n",
      "\n",
      "analyzing  /wiki/Onion ...\n",
      "analyzing  /wiki/Pearl_onion ...\n",
      "No information for  Pearl onion \n",
      "\n",
      "analyzing  /wiki/Potato_onion ...\n",
      "No information for  Potato onion \n",
      "\n",
      "analyzing  /wiki/Ornithogalum_pyrenaicum ...\n",
      "No information for  Ornithogalum pyrenaicum \n",
      "\n",
      "analyzing  /wiki/Scallion ...\n",
      "No information for  Scallion \n",
      "\n",
      "analyzing  /wiki/Shallot ...\n",
      "analyzing  /wiki/Tree_onion ...\n",
      "No information for  Tree onion \n",
      "\n",
      "analyzing  /wiki/Welsh_onion ...\n",
      "analyzing  /wiki/Allium_tricoccum ...\n",
      "No information for  Allium tricoccum \n",
      "\n",
      "analyzing  /wiki/Zizania_latifolia ...\n",
      "No information for  Zizania latifolia \n",
      "\n",
      "analyzing  /wiki/Pachyrhizus ...\n",
      "No information for  Pachyrhizus \n",
      "\n",
      "analyzing  /wiki/Arracacha ...\n",
      "No information for  Arracacia xanthorrhiza \n",
      "\n",
      "analyzing  /wiki/Bamboo_shoot ...\n",
      "analyzing  /wiki/Beet ...\n",
      "analyzing  /wiki/Burdock ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No information for  Arctium \n",
      "\n",
      "analyzing  /wiki/Broadleaf_arrowhead ...\n",
      "analyzing  /wiki/Camassia ...\n",
      "No information for  Camassia \n",
      "\n",
      "analyzing  /wiki/Canna_(plant) ...\n",
      "No information for  Canna (plant) \n",
      "\n",
      "analyzing  /wiki/Carrot ...\n",
      "analyzing  /wiki/Cassava ...\n",
      "analyzing  /wiki/Chinese_artichoke ...\n",
      "No information for  Stachys affinis \n",
      "\n",
      "analyzing  /wiki/Daikon ...\n",
      "analyzing  /wiki/Lathyrus_tuberosus ...\n",
      "No information for  Lathyrus tuberosus \n",
      "\n",
      "analyzing  /wiki/Amorphophallus_paeoniifolius ...\n",
      "No information for  Amorphophallus paeoniifolius \n",
      "\n",
      "analyzing  /wiki/Ensete ...\n",
      "No information for  Ensete \n",
      "\n",
      "analyzing  /wiki/Galangal ...\n",
      "No information for  Galangal \n",
      "\n",
      "analyzing  /wiki/Ginger ...\n",
      "analyzing  /wiki/Parsley ...\n",
      "analyzing  /wiki/Horseradish ...\n",
      "No information for  Horseradish \n",
      "\n",
      "analyzing  /wiki/Jerusalem_artichoke ...\n",
      "analyzing  /wiki/J%C3%ADcama ...\n",
      "analyzing  /wiki/Mashua ...\n",
      "No information for  Tropaeolum tuberosum \n",
      "\n",
      "analyzing  /wiki/Parsnip ...\n",
      "analyzing  /wiki/Conopodium_majus ...\n",
      "No information for  Conopodium majus \n",
      "\n",
      "analyzing  /wiki/Potato ...\n",
      "No information for  Potato \n",
      "\n",
      "analyzing  /wiki/Psoralea_esculenta ...\n",
      "No information for  Psoralea esculenta \n",
      "\n",
      "analyzing  /wiki/Radish ...\n",
      "analyzing  /wiki/Rutabaga ...\n",
      "analyzing  /wiki/Purple_Salsify ...\n",
      "analyzing  /wiki/Black_salsify ...\n",
      "No information for  Scorzonera hispanica \n",
      "\n",
      "analyzing  /wiki/Skirret ...\n",
      "No information for  Sium sisarum \n",
      "\n",
      "analyzing  /wiki/Rutabaga ...\n",
      "analyzing  /wiki/Sweet_potato ...\n",
      "analyzing  /wiki/Taro ...\n",
      "analyzing  /wiki/Ti_(plant) ...\n",
      "No information for  Cordyline fruticosa \n",
      "\n",
      "analyzing  /wiki/Cyperus_esculentus ...\n",
      "No information for  Cyperus esculentus \n",
      "\n",
      "analyzing  /wiki/Turmeric ...\n",
      "No information for  Turmeric \n",
      "\n",
      "analyzing  /wiki/Turnip ...\n",
      "analyzing  /wiki/Ulluco ...\n",
      "analyzing  /wiki/Wasabi ...\n",
      "No information for  Wasabi \n",
      "\n",
      "analyzing  /wiki/Water_caltrop ...\n",
      "No information for  Water caltrop \n",
      "\n",
      "analyzing  /wiki/Eleocharis_dulcis ...\n",
      "analyzing  /wiki/Yac%C3%B3n ...\n",
      "No information for  Yacón \n",
      "\n",
      "analyzing  /wiki/Yam_(vegetable) ...\n",
      "analyzing  /wiki/Aonori ...\n",
      "No information for  Green laver \n",
      "\n",
      "analyzing  /wiki/Arame ...\n",
      "No information for  Arame \n",
      "\n",
      "analyzing  /wiki/Carola_(sea_vegetable) ...\n",
      "No information for  Callophyllis \n",
      "\n",
      "analyzing  /wiki/Alaria_esculenta ...\n",
      "No information for  Alaria esculenta \n",
      "\n",
      "analyzing  /wiki/Palmaria_palmata ...\n",
      "No information for  Palmaria palmata \n",
      "\n",
      "analyzing  /wiki/Hijiki ...\n",
      "No information for  Hijiki \n",
      "\n",
      "analyzing  /wiki/Kombu ...\n",
      "No information for  Kombu \n",
      "\n",
      "analyzing  /wiki/Laver_(seaweed) ...\n",
      "analyzing  /wiki/Mozuku ...\n",
      "No information for  Cladosiphon okamuranus \n",
      "\n",
      "analyzing  /wiki/Nori ...\n",
      "analyzing  /wiki/Ogonori ...\n",
      "No information for  Gracilaria \n",
      "\n",
      "analyzing  /wiki/Caulerpa ...\n",
      "No information for  Caulerpa \n",
      "\n",
      "analyzing  /wiki/Sea_lettuce ...\n",
      "No information for  Sea lettuce \n",
      "\n",
      "analyzing  /wiki/Wakame ...\n",
      "analyzing  /wiki/Abiu ...\n",
      "No information for  Pouteria caimito \n",
      "\n",
      "analyzing  /wiki/A%C3%A7a%C3%AD ...\n",
      "No information for  Açaí palm \n",
      "\n",
      "analyzing  /wiki/Acerola ...\n",
      "analyzing  /wiki/Ackee ...\n",
      "No information for  Ackee \n",
      "\n",
      "analyzing  /wiki/Citropsis_articulata ...\n",
      "No information for  Citropsis articulata \n",
      "\n",
      "analyzing  /wiki/African_mango ...\n",
      "No information for  Irvingia gabonensis \n",
      "\n",
      "analyzing  /w/index.php?title=African_horseradish_tree&action=edit&redlink=1 ...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'food' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cd83d9e4a8a1>\u001b[0m in \u001b[0;36mnutritional_facts\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mtry\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"html5lib\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    641\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 642\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    641\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 642\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5c3ca45d814d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mname_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"analyzing \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnutritional_facts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://en.wikipedia.org/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-cd83d9e4a8a1>\u001b[0m in \u001b[0;36mnutritional_facts\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No information for \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfood\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'food' referenced before assignment"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(columns = np.append(elements_names, 'name'))\n",
    "row = -1\n",
    "name_index = -1\n",
    "for url in all_urls :\n",
    "    name_index = name_index + 1\n",
    "    print(\"analyzing \", url, \"...\")\n",
    "    nv = nutritional_facts(\"https://en.wikipedia.org/\" + url)\n",
    "    \n",
    "    if nv is not None :\n",
    "        row = row + 1\n",
    "        nv['name'] = all_names[name_index]\n",
    "        \n",
    "        for k in nv.keys() :            \n",
    "            dataframe.loc[row,k] = nv[k]\n",
    "        \n",
    "print(\"percentage of parsed information : \", 100 * len(dataframe.index) / len(all_urls))      \n",
    "dataframe.set_index(\"name\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
